{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c4855fb"
      },
      "source": [
        "# Лабораторная работа 3. Распознавание многозначных чисел\n",
        "\n",
        "Цель: Используя код из лабораторной работы № 2 обучить нейросеть распознавать рукописные многозначные числа.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wget # Пакет wget для скачивания файлов из Интернета"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT1a3jLc-5j1",
        "outputId": "e11de6d3-7fa8-49a8-de8d-3666667951d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=a3775ffd3ba8fe2114f6c42cfdda4036ca4c0d89f4f360c941b37bfba78e5ca3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "for index in range(10):\n",
        "  as_str = str(index)\n",
        "  as_str += \".bmp\"\n",
        "  wget.download('http://xyla.istu.webappz.ru/neuron/'+as_str)\n",
        "wget.download(('http://xyla.istu.webappz.ru/neuron/mnist.pkl.gz'))\n",
        "# база данных MNIST содержит 70 000 изображений рукописных цифр, разделенных на три набора:\n",
        "# training_data – набор из 50 000 изображений предназначен для обучения нейронных сетей;\n",
        "# validation_data – набор из 10 000 изображений предназначен для текущей оценки работы алгоритма обучения и подбора параметров обучения (используется в последующих лабораторных работах);\n",
        "# test_data – набор из 10 000 изображений предназначен для проверки работы нейронной сетей.\n",
        "# Каждый набор состоит из двух списков: списка изображений (в градациях серого) и соответствующего списка цифр в диапазоне от 0 до 9 Изображение представлено в виде одномерного numpy-массива размера 784 = 28 × 28 значений от 0 до 1, где 0 соответствует черному цвету пиксела, а 1 – белому."
      ],
      "metadata": {
        "id": "rj9rW98q8ToI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0729469e-6cf6-43b3-c887-334774b030b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mnist.pkl.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NGa6JYzb6KD4"
      },
      "outputs": [],
      "source": [
        "# В качестве функции активации для нейронов сети используется сигмоидальная функция, вычисляющая выходной сигнал искусственного нейрона\n",
        "def sigmoid(z): # определение сигмоидальной функции активации\n",
        "    return 1.0/(1.0+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Данный метод осуществляет подсчет выходных сигналов нейронной сети при заданных входных сигналах.\n",
        "# Параметр a является массивом n × 1, где n – количество нейронов входного слоя. Функция np.dot вычисляет произведение матриц.\n",
        "# Для подсчета выходных значений нейронной сети, необходимо один раз вызвать метод feedforward, в результате чего выходные сигналы будут последовательно вычислены для всех слоев нейронной сети.\n",
        "def feedforward(self, a):\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "        a = sigmoid(np.dot(w, a)+b)\n",
        "    return a"
      ],
      "metadata": {
        "id": "KJWHglcb6N5W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для реализации механизма обучения создаваемой нейронной сети добавим метод SGD, который реализует стохастический градиентный спуск. Метод имеет следующие параметры:\n",
        "# «Training_data» – обучающая выборка, состоящая из пар вида ( , ), где – вектор входных сигналов, а – ожидаемый вектор выходных сигналов;\n",
        "# «epochs» – количество эпох обучения;\n",
        "# «mini_batch_size» - размер подвыборки;\n",
        "# «eta» - скорость обучения;\n",
        "# «test_data» - (необязательный параметр); если данный аргумент не пуст, то программа после каждой эпохи обучения осуществляет оценку работы сети и показывает достигнутый прогресс.\n",
        "def SGD(                                      # Стохастический градиентный спуск\n",
        "          self                                # указатель на объект класса\n",
        "        , training_data                       # обучающая выборка\n",
        "        , epochs                              # количество эпох обучения\n",
        "        , mini_batch_size                     # размер подвыборки\n",
        "        , eta                                 # скорость обучения\n",
        "        , test_data                           # тестирующая выборка\n",
        "        ):\n",
        "    test_data = list(test_data)               # создаем список объектов тестирующей выборки\n",
        "    n_test = len(test_data)                   # вычисляем длину тестирующей выборки\n",
        "    training_data = list(training_data)       # создаем список объектов обучающей выборки\n",
        "    n = len(training_data)                    # вычисляем размер обучающей выборки\n",
        "    for j in range(epochs):                   # цикл по эпохам\n",
        "        random.shuffle(training_data)         # перемешиваем элементы обучающей выборки\n",
        "        mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]   # создаем подвыборки\n",
        "        for mini_batch in mini_batches:                                                             # цикл по подвыборкам\n",
        "            self.update_mini_batch(mini_batch, eta)                                                 # один шаг градиентного спуска\n",
        "        print (\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test))                  # смотрим прогресс в обучении\n",
        "        with open('biases.pkl', 'wb') as f:\n",
        "            pickle.dump(self.biases, f)\n",
        "        with open('weights.pkl', 'wb') as f:\n",
        "            pickle.dump(self.weights, f)"
      ],
      "metadata": {
        "id": "xU8JsShv6QAO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метод update_mini_batch вычисляет градиенты для каждого прецедента в подвыборке, а затем соответствующим образом обновляет веса и смещения нейронной сети\n",
        "def update_mini_batch(                  # Шаг градиентного спуска\n",
        "                      self              # указатель на объект класса\n",
        "                    , mini_batch        # подвыборка\n",
        "                    , eta               # скорость обучения\n",
        "                    ):\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]      # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]     # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "    for x, y in mini_batch:\n",
        "        delta_nabla_b, delta_nabla_w = self.backprop(x, y)  # послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\n",
        "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # суммируем градиенты dC/db для различных прецедентов текущей подвыборки\n",
        "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)] # суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\n",
        "    self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] # обновляем все веса w нейронной сети\n",
        "    self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] # обновляем все смещения b нейронной сети"
      ],
      "metadata": {
        "id": "4IXUfZwe6Spn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(                     # Алгоритм обратного распространения\n",
        "              self                # указатель на объект класса\n",
        "            , x                   # вектор входных сигналов\n",
        "            , y                   # ожидаемый вектор выходных сигналов\n",
        "            ):\n",
        "    nabla_b = [np.zeros(b.shape) for b in self.biases]      # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.weights]     # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "\n",
        "    # определение переменных\n",
        "    activation = x                                          # выходные сигналы слоя (первоначально соответствует выходным сигналам 1-го слоя или входным сигналам сети)\n",
        "    activations = [x]                                       # список выходных сигналов по всем слоям (первоначально содержит только выходные сигналы 1-го слоя)\n",
        "    zs = []                                                 # список активационных потенциалов по всем слоям (первоначально пуст)\n",
        "\n",
        "    # прямое распространение\n",
        "    for b, w in zip(self.biases, self.weights):\n",
        "        z = np.dot(w, activation)+b                         # считаем активационные потенциалы текущего слоя\n",
        "        zs.append(z)                                        # добавляем элемент (активационные потенциалы слоя) в конец списка\n",
        "        activation = sigmoid(z)                             # считаем выходные сигналы текущего слоя, применяя сигмоидальную функцию активации к активационным потенциалам слоя\n",
        "        activations.append(activation)                      # добавляем элемент (выходные сигналы слоя) в конец списка\n",
        "\n",
        "    # обратное распространение\n",
        "    delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])    # считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\n",
        "    nabla_b[-1] = delta                                                         # градиент dC/db для слоя L (BP3)\n",
        "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())                    # градиент dC/dw для слоя L (BP4)\n",
        "    for l in range(2, self.num_layers):\n",
        "        z = zs[-l]                                                              # активационные потенциалы l-го слоя (двигаемся \"Положение EcoRobotics.docx\"списку справа налево)\n",
        "        sp = sigmoid_prime(z)                                                   # считаем сигмоидальную функцию от активационных потенциалов l-го слоя\n",
        "        delta = np.dot(self.weights[-l+1].transpose(), delta) * sp              # считаем меру влияния нейронов l-го слоя на величину ошибки (BP2)\n",
        "        nabla_b[-l] = delta                                                     # градиент dC/db для l-го слоя (BP3)\n",
        "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())              # градиент dC/dw для l-го слоя (BP4)\n",
        "    return (nabla_b, nabla_w)"
      ],
      "metadata": {
        "id": "D-kMVF8V6VbY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Метод возвращает количество прецедентов тестирующей выборки, для которых нейронная сеть выдает правильный результат\n",
        "# Тестирующая выборка состоит из пар (x, y), где x – вектор размерности 784, содержащий изображение цифры, а y – целое числовое значение цифры, изображенной на картинке\n",
        "# Ответ нейронной сети определяется как номер нейрона в выходном слое, имеющего наибольшее значение функции активации\n",
        "# Метод evaluate вызывается в методе SGD после завершения очередной эпохи обучения\n",
        "def evaluate(self, test_data): # Оценка прогресса в обучении\n",
        "    test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "    return sum(int(x == y) for (x, y) in test_results)"
      ],
      "metadata": {
        "id": "E5LX_6LA6X7U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисление частных производных стоимостной функции по выходным сигналам последнего слоя\n",
        "def cost_derivative(self, output_activations, y): # Вычисление частных производных стоимостной функции по выходным сигналам последнего слоя\n",
        "    return (output_activations-y)"
      ],
      "metadata": {
        "id": "LaxiSsz96ZI_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_prime(z):# Производная сигмоидальной функции\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ],
      "metadata": {
        "id": "6BVbJbWO6aip"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функции для работы с базой данных MNIST\n",
        "import gzip           # библиотека для сжатия и распаковки файлов gzip и gunzip.\n",
        "import pickle         # библиотека для сохранения и загрузки сложных объектов Python.\n",
        "import numpy as np    # библиотека для работы с матрицами\n",
        "\n",
        "def load_data():\n",
        "    f = gzip.open('mnist.pkl.gz', 'rb')                                             # открываем сжатый файл gzip в двоичном режиме\n",
        "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')   # загружам таблицы из файла\n",
        "    f.close()                                                                       # закрываем файл\n",
        "    return (training_data, validation_data, test_data)"
      ],
      "metadata": {
        "id": "CVN6SoRt6b-b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для преобразования числа в вектор-столбец (10-мерный numpy массив), используется следующая функция vectorized_result.\n",
        "def vectorized_result(j):\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1\n",
        "    return e"
      ],
      "metadata": {
        "id": "r1Pmm3vp6dUF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для использования базы данных MNIST в нашей программе необходимо скорректировать форматы наборы training_data, validation_data и test_data\n",
        "# Это делается в функции load_data_wrapper\n",
        "def load_data_wrapper():\n",
        "    tr_d, va_d, te_d = load_data()                                  # инициализация наборов данных в формате MNIST\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]    # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    training_results = [vectorized_result(y) for y in tr_d[1]]      # представление цифр от 0 до 9 в виде массивов размера 10 на 1\n",
        "    training_data = zip(training_inputs, training_results)          # формируем набор обучающих данных из пар (x, y)\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]  # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    validation_data = zip(validation_inputs, va_d[1])               # формируем набор данных проверки из пар (x, y)\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]        # преобразование массивов размера 1 на 784 к массивам размера 784 на 1\n",
        "    test_data = zip(test_inputs, te_d[1])                           # формируем набор тестовых данных из пар (x, y)\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "training_data, validation_data,test_data = load_data_wrapper()\n",
        "# Данная функция преобразует training_data в список, содержащий 50 000 пар (x, y), где x является 784-мерным numpy-массивом, содержащим входное изображение\n",
        "# а y – это 10-мерный numpy-массив, представляющий собой вектор, у которого координата с порядковым номером, соответствующим цифре на изображении\n",
        "# равняется единице, а остальные координаты нулевые. Аналогичные преобразования делаются для наборов validation_data и test_data."
      ],
      "metadata": {
        "id": "miUqaV_c6ekV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # библиотека функций для работы с матрицами\n",
        "import pickle\n",
        "\n",
        "def sigmoid(z): # определение сигмоидальной функции активации\n",
        "    return 1.0/(1.0+np.exp(-z))"
      ],
      "metadata": {
        "id": "0eLl-ebf6gB2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.display import exists\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "Модуль создания и обучения нейронной сети для распознавания рукописных цифр с использованием метода градиентного спуска.\n",
        "Группа: АСУб-20-2\n",
        "ФИО: Арбакова Анастасия Вячеславовна\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "#### Библиотеки\n",
        "# Стандартные библиотеки\n",
        "import random               # библиотека функций для генерации случайных значений\n",
        "import os.path\n",
        "\n",
        "# Сторонние библиотеки\n",
        "import numpy as np          # библиотека функций для работы с матрицами\n",
        "\n",
        "\"\"\" ---Раздел описаний--- \"\"\"\n",
        "\"\"\" --Описание класса Network--\"\"\"\n",
        "class Network(object):                    # используется для описания нейронной сети\n",
        "    def __init__(self, sizes):            # конструктор класса, self – указатель на объект класса, sizes – список размеров слоев нейронной сети\n",
        "        self.num_layers = len(sizes)      # задаем количество слоев нейронной сети\n",
        "        self.sizes = sizes                # задаем список размеров слоев нейронной сети\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]                          # задаем случайные начальные смещения\n",
        "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]     # задаем случайные начальные веса связей\n",
        "        if(os.path.isfile('biases.pkl')):\n",
        "          with open('biases.pkl', 'rb') as f:     #открытие файла со смещениями\n",
        "            self.biases = pickle.load(f)\n",
        "        if(os.path.isfile('weights.pkl')):\n",
        "          with open('weights.pkl', 'rb') as f:    #открытие файла с весами\n",
        "            self.weights = pickle.load(f)\n",
        "\n",
        "    # В качестве функции активации для нейронов сети используется сигмоидальная функция, вычисляющая выходной сигнал искусственного нейрона\n",
        "    def sigmoid(z):                               # определение сигмоидальной функции активации\n",
        "        return 1.0/(1.0+np.exp(-z))\n",
        "    def feedforward(self, a):                     # подсчет выходных сигналов нейронной сети при заданных входных сигналах\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "    # Метод возвращает количество прецедентов тестирующей выборки, для которых нейронная сеть выдает правильный результат\n",
        "    def evaluate(self, test_data):      # Оценка прогресса в обучении\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y): # Вычисление частных производных стоимостной функции по выходным сигналам последнего слоя\n",
        "        return (output_activations-y)\n",
        "\n",
        "    def backprop(           # Алгоритм обратного распространения\n",
        "              self          # указатель на объект класса\n",
        "            , x             # вектор входных сигналов\n",
        "            , y             # ожидаемый вектор выходных сигналов\n",
        "            ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]        # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]       # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "\n",
        "        # определение переменных\n",
        "        activation = x                                            # выходные сигналы слоя (первоначально соответствует выходным сигналам 1-го слоя или входным сигналам сети)\n",
        "        activations = [x]                                         # список выходных сигналов по всем слоям (первоначально содержит только выходные сигналы 1-го слоя)\n",
        "        zs = []                                                   # список активационных потенциалов по всем слоям (первоначально пуст)\n",
        "\n",
        "        # прямое распространение\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b                           # считаем активационные потенциалы текущего слоя\n",
        "            zs.append(z)                                          # добавляем элемент (активационные потенциалы слоя) в конец списка\n",
        "            activation = sigmoid(z)                               # считаем выходные сигналы текущего слоя, применяя сигмоидальную функцию активации к активационным потенциалам слоя\n",
        "            activations.append(activation)                        # добавляем элемент (выходные сигналы слоя) в конец списка\n",
        "\n",
        "        # обратное распространение\n",
        "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])      # считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\n",
        "        nabla_b[-1] = delta                                                           # градиент dC/db для слоя L (BP3)\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())                      # градиент dC/dw для слоя L (BP4)\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l]                                                                # активационные потенциалы l-го слоя (двигаемся \"Положение EcoRobotics.docx\"списку справа налево)\n",
        "            sp = sigmoid_prime(z)                                                     # считаем сигмоидальную функцию от активационных потенциалов l-го слоя\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp                # считаем меру влияния нейронов l-го слоя на величину ошибки (BP2)\n",
        "            nabla_b[-l] = delta                                                       # градиент dC/db для l-го слоя (BP3)\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())                # градиент dC/dw для l-го слоя (BP4)\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    # Метод update_mini_batch вычисляет градиенты для каждого прецедента в подвыборке, а затем соответствующим образом обновляет веса и смещения нейронной сети\n",
        "    def update_mini_batch(        # Шаг градиентного спуска\n",
        "                      self        # указатель на объект класса\n",
        "                    , mini_batch  # подвыборка\n",
        "                    , eta         # скорость обучения\n",
        "                    ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]                            # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]                           # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)                        # послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]             # суммируем градиенты dC/db для различных прецедентов текущей подвыборки\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]             # суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] # обновляем все веса w нейронной сети\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] # обновляем все смещения b нейронной сети\n",
        "\n",
        "# 1\n",
        "    # Для реализации механизма обучения создаваемой нейронной сети добавим метод SGD, который реализует стохастический градиентный спуск\n",
        "    def SGD(              # Стохастический градиентный спуск\n",
        "          self            # указатель на объект класса\n",
        "        , training_data   # обучающая выборка\n",
        "        , epochs          # количество эпох обучения\n",
        "        , mini_batch_size # размер подвыборки\n",
        "        , eta             # скорость обучения\n",
        "        , test_data       # тестирующая выборка\n",
        "        ):\n",
        "        test_data = list(test_data)         # создаем список объектов тестирующей выборки\n",
        "        n_test = len(test_data)             # вычисляем длину тестирующей выборки\n",
        "        training_data = list(training_data) # создаем список объектов обучающей выборки\n",
        "        n = len(training_data)              # вычисляем размер обучающей выборки\n",
        "        for j in range(epochs):             # цикл по эпохам\n",
        "            random.shuffle(training_data)   # перемешиваем элементы обучающей выборки\n",
        "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)] # создаем подвыборки\n",
        "            for mini_batch in mini_batches: # цикл по подвыборкам\n",
        "                self.update_mini_batch(mini_batch, eta) # один шаг градиентного спуска\n",
        "            print (\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test)) # смотрим прогресс в обучении\n",
        "            with open('biases.pkl', 'wb') as f:\n",
        "                pickle.dump(self.biases, f)\n",
        "            with open('weights.pkl', 'wb') as f:\n",
        "                pickle.dump(self.weights, f)\n",
        "        \"\"\" --Конец описания класса Network--\"\"\"\n",
        "\"\"\" --- Конец раздела описаний--- \"\"\"\n",
        "\n",
        "\"\"\" ---Тело программы--- \"\"\"\n",
        "net = Network([2, 3, 1])                    # создаем нейронную сеть из трех слоев\n",
        "\"\"\" ---Конец тела программы--- \"\"\"\n",
        "\"\"\" Вывод результата на экран: \"\"\"\n",
        "print('Сеть net:')\n",
        "print('Количетво слоев:', net.num_layers)\n",
        "for i in range(net.num_layers):\n",
        "    print('Количество нейронов в слое', i,':',net.sizes[i])\n",
        "for i in range(net.num_layers-1):\n",
        "    print('W_',i+1,':')\n",
        "    print(np.round(net.weights[i],2))\n",
        "    print('b_',i+1,':')\n",
        "    print(np.round(net.biases[i],2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sDz256k6hW8",
        "outputId": "8caa50fa-d8ba-4773-b7d5-faa430dea6fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сеть net:\n",
            "Количетво слоев: 3\n",
            "Количество нейронов в слое 0 : 2\n",
            "Количество нейронов в слое 1 : 3\n",
            "Количество нейронов в слое 2 : 1\n",
            "W_ 1 :\n",
            "[[ 0.82  0.65]\n",
            " [ 0.8  -0.37]\n",
            " [-0.41 -0.92]]\n",
            "b_ 1 :\n",
            "[[ 1.  ]\n",
            " [ 1.33]\n",
            " [-0.8 ]]\n",
            "W_ 2 :\n",
            "[[-1.15  0.73 -0.21]]\n",
            "b_ 2 :\n",
            "[[0.92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network([784, 30, 10])\n",
        "# Параметры, указанные при вызове данного метода, определяют топологию создаваемой сети\n",
        "# Таким образом, в результате выполнения команды будет создана сеть, состоящая из трех слоев:\n",
        "# входной слой сети состоит из 784-х нейронов\n",
        "# внутренний слой из 30 нейронов\n",
        "# выходной слой из 10 нейронов"
      ],
      "metadata": {
        "id": "Ox0G6Jf_6i7m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.SGD(training_data, 30, 10, 3.0, test_data=test_data) # процедура обучения созданной нейронной сети, включающая 30 эпох\n",
        "# Параметры, указанные при вызове метода SGD:\n",
        "# обучающая выборка\n",
        "# количество эпох обучения\n",
        "# размер подвыборки\n",
        "# скорость обучения\n",
        "# тестирующая выборка\n",
        "# Обучение может занять несколько минут. В ходе обучения будет выдаваться информация о пройденных эпохах.\n",
        "# Для каждой эпохи выводится отношение количества правильно распознанных цифр к общему количеству цифр в тестовой выборке.\n",
        "# Например, запись Epoch 6: 9374 / 10000 говорит о том, что в результате\n",
        "# эпохи обучения с номером 6 достигнута точность распознавания ≈ 0.94, что составляет 94%."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwdcXv056kPg",
        "outputId": "c27c3583-c394-4c5b-cff7-826890fa389d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 9062 / 10000\n",
            "Epoch 1: 9285 / 10000\n",
            "Epoch 2: 9303 / 10000\n",
            "Epoch 3: 9369 / 10000\n",
            "Epoch 4: 9394 / 10000\n",
            "Epoch 5: 9418 / 10000\n",
            "Epoch 6: 9405 / 10000\n",
            "Epoch 7: 9459 / 10000\n",
            "Epoch 8: 9443 / 10000\n",
            "Epoch 9: 9464 / 10000\n",
            "Epoch 10: 9458 / 10000\n",
            "Epoch 11: 9473 / 10000\n",
            "Epoch 12: 9500 / 10000\n",
            "Epoch 13: 9494 / 10000\n",
            "Epoch 14: 9519 / 10000\n",
            "Epoch 15: 9492 / 10000\n",
            "Epoch 16: 9512 / 10000\n",
            "Epoch 17: 9513 / 10000\n",
            "Epoch 18: 9505 / 10000\n",
            "Epoch 19: 9530 / 10000\n",
            "Epoch 20: 9520 / 10000\n",
            "Epoch 21: 9531 / 10000\n",
            "Epoch 22: 9521 / 10000\n",
            "Epoch 23: 9508 / 10000\n",
            "Epoch 24: 9520 / 10000\n",
            "Epoch 25: 9520 / 10000\n",
            "Epoch 26: 9523 / 10000\n",
            "Epoch 27: 9525 / 10000\n",
            "Epoch 28: 9531 / 10000\n",
            "Epoch 29: 9535 / 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_concat_h(im1, im2):\n",
        "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
        "    dst.paste(im1, (0, 0))\n",
        "    dst.paste(im2, (im1.width, 0))\n",
        "    return dst"
      ],
      "metadata": {
        "id": "55cg6IIKF3k4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "number =  input(\"Введите число: \")\n",
        "num_arr = [int(a) for a in str(number)]\n",
        "print (num_arr)\n",
        "img = Image.open(str(num_arr[0])+'.bmp')\n",
        "for index in range(len(num_arr)):\n",
        "  if(index != 0):\n",
        "    img = get_concat_h(img,Image.open(str(num_arr[index])+'.bmp'))\n",
        "display(img)"
      ],
      "metadata": {
        "id": "h4mDAWdiBGGX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b1d1c7d1-8ee3-47f8-da8a-6e17a88a306e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите число: 56789\n",
            "[5, 6, 7, 8, 9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=140x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAAAcCAIAAAA8xMAqAAACUklEQVR4nO1YyZHDMAxTKS5FpbgUleJHClEhKSL/PLIP78i0ThCSc8wIs7+1aRAgKSrGTExMTExMDIW11t/9Kwd/9+vq0EDOudfzkQ3EB70AlYS/k/C6toR9PtBYeNqKoAlKEuNSqhzSEu6nF2FdHcgR+gSe8rbdCLrGGGttraYwKZ1D05YAGdZLXmuVtfZ41/tlseFfy2K37aZW4ODX0SgVukgHjP1iCItUFTpFnw/Qp6giS49FVjWCygpFSKgQVWik2v5pukFTgAJJSIdk1WdKHitiScB733gYp3qhSWWHroAUCPxcU1Bp1ZCA2YcVcRESKlwXOYV20O0Ig0SeHBLa1lQdH4xJWdAbjlSNeF0LrZo7woR0zuX/qzReHh916XT6tO9J1E7BqcaBayNzJpk2E5dCpGfJKl1wZLvFKR4khMf/fzn03zqlQ9qAklX0Fm18U09/9/KZ3tN6jElNwAuuRG17hls/EjQMPWJRrEeugAh+oPNQUZh0FghE5X7DFH71uk33etMqvo3SIiWCpGmnhE45KE++NH+CJH6ZJYKXoO5RhCXnNn5N5lSOJhJHMrp7Wpv72YatgCJtLeeLHNoRggzbROVb3Q6Z80zOXpXCV7TTuPhF4qirDM3+3wiayyh3Po9yyABNfOiDTbx9MpU2THpjvBClCthz4LQe6JDBJq2qhtLJJA17591RAXATxbWWKgzs9crtSiXr8HzfilFzNcQZkmfEKj+QNSalMX/GIYkoh48zLq1zKVRhS1Z9PN9fBTKjprhfgUsX3YmJibfjD9RCw77+h38VAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy\n",
        "\n",
        "for index in range(len(num_arr)):\n",
        "    as_str = str(num_arr[index])\n",
        "    as_str += \".bmp\"\n",
        "    im=Image.open(as_str) #открытие рисунка с 2-кой\n",
        "    testArray=numpy.ndarray(shape=(784, 1), dtype=float, order='F') #создание контейнера для копирования значения пикселей изображения\n",
        "\n",
        "    #операция копирования в контейнер пикселей изображения\n",
        "    for i2 in range(28):\n",
        "        for i1 in range(28):\n",
        "            if (im.getpixel((i1, i2))) / 255 > 0:\n",
        "                #вынужден был применять костыль, т.к. 1 в значении пикселей нейросеть неадекватно воспринимает\n",
        "                testArray[i1 + i2 * 28, 0] = (im.getpixel((i1, i2))) / 255 - 0.001\n",
        "            else:\n",
        "                testArray[i1 + i2 * 28,0] = (im.getpixel((i1, i2))) / 255\n",
        "\n",
        "    netSm = Network([784, 30, 10]) #создаем нейросеть с обученными весами и смещениями\n",
        "    print(as_str)\n",
        "    display(im)\n",
        "    print(netSm.feedforward(testArray)) #распознаем изображение с помощью нейросети\n",
        "    print(as_str)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RHNJbV8c6lnf",
        "outputId": "75e65454-c2ae-416c-986a-78393b24b1ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.bmp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.BmpImagePlugin.BmpImageFile image mode=P size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgIDAwMDA3MCmyvBAIABgIACAIACgIADAIADgIAAAQAAgQABAQABgQACAQACgQADAQADgQAAAYAAgYABAYABgYACAYACgYADAYADgYAAAgAAggABAgABggACAgACggADAgADggAAAoAAgoABAoABgoACAoACgoADAoADgoAAAwAAgwABAwABgwACAwACgwADAwADgwAAA4AAg4ABA4ABg4ACA4ACg4ADA4ADg4AAAAEAgAEBAAEBgAECAAECgAEDAAEDgAEAAIEAgIEBAIEBgIECAIECgIEDAIEDgIEAAQEAgQEBAQEBgQECAQECgQEDAQEDgQEAAYEAgYEBAYEBgYECAYECgYEDAYEDgYEAAgEAggEBAgEBggECAgECggEDAgEDggEAAoEAgoEBAoEBgoECAoECgoEDAoEDgoEAAwEAgwEBAwEBgwECAwECgwEDAwEDgwEAA4EAg4EBA4EBg4ECA4ECg4EDA4EDg4EAAAIAgAIBAAIBgAICAAICgAIDAAIDgAIAAIIAgIIBAIIBgIICAIICgIIDAIIDgIIAAQIAgQIBAQIBgQICAQICgQIDAQIDgQIAAYIAgYIBAYIBgYICAYICgYIDAYIDgYIAAgIAggIBAgIBggICAgICggIDAgIDggIAAoIAgoIBAoIBgoICAoICgoIDAoIDgoIAAwIAgwIBAwIBgwICAwICgwIDAwIDgwIAA4IAg4IBA4IBg4ICA4ICg4IDA4IDg4IAAAMAgAMBAAMBgAMCAAMCgAMDAAMDgAMAAIMAgIMBAIMBgIMCAIMCgIMDAIMDgIMAAQMAgQMBAQMBgQMCAQMCgQMDAQMDgQMAAYMAgYMBAYMBgYMCAYMCgYMDAYMDgYMAAgMAggMBAgMBggMCAgMCggMDAgMDggMAAoMAgoMBAoMBgoMCAoMCgoMDAoMDgoMAAwMAgwMBAwMBgwMCAwMCgwMD/+/CgoKSAgID/AAAA/wD//wAAAP//AP8A//////9Y0jREAAAATklEQVR4nGNgGCiw5Nt/BOCYjSr5HwV8wyf5HVXyG4ZyZDuB6nG7iCJJHB6BuAiHR6AuggHyLA/CLRnEgc1YiCjWwGNgwCeHcCym1EgAAAE0hQ5/oATtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.00200886e-09]\n",
            " [6.09720659e-06]\n",
            " [3.16750981e-06]\n",
            " [3.69913075e-08]\n",
            " [3.97812473e-02]\n",
            " [4.21910483e-07]\n",
            " [2.07425563e-02]\n",
            " [1.57541749e-08]\n",
            " [1.02441385e-03]\n",
            " [9.49353098e-04]]\n",
            "5.bmp\n",
            "\n",
            "6.bmp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.BmpImagePlugin.BmpImageFile image mode=P size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgIDAwMDA3MCmyvBAIABgIACAIACgIADAIADgIAAAQAAgQABAQABgQACAQACgQADAQADgQAAAYAAgYABAYABgYACAYACgYADAYADgYAAAgAAggABAgABggACAgACggADAgADggAAAoAAgoABAoABgoACAoACgoADAoADgoAAAwAAgwABAwABgwACAwACgwADAwADgwAAA4AAg4ABA4ABg4ACA4ACg4ADA4ADg4AAAAEAgAEBAAEBgAECAAECgAEDAAEDgAEAAIEAgIEBAIEBgIECAIECgIEDAIEDgIEAAQEAgQEBAQEBgQECAQECgQEDAQEDgQEAAYEAgYEBAYEBgYECAYECgYEDAYEDgYEAAgEAggEBAgEBggECAgECggEDAgEDggEAAoEAgoEBAoEBgoECAoECgoEDAoEDgoEAAwEAgwEBAwEBgwECAwECgwEDAwEDgwEAA4EAg4EBA4EBg4ECA4ECg4EDA4EDg4EAAAIAgAIBAAIBgAICAAICgAIDAAIDgAIAAIIAgIIBAIIBgIICAIICgIIDAIIDgIIAAQIAgQIBAQIBgQICAQICgQIDAQIDgQIAAYIAgYIBAYIBgYICAYICgYIDAYIDgYIAAgIAggIBAgIBggICAgICggIDAgIDggIAAoIAgoIBAoIBgoICAoICgoIDAoIDgoIAAwIAgwIBAwIBgwICAwICgwIDAwIDgwIAA4IAg4IBA4IBg4ICA4ICg4IDA4IDg4IAAAMAgAMBAAMBgAMCAAMCgAMDAAMDgAMAAIMAgIMBAIMBgIMCAIMCgIMDAIMDgIMAAQMAgQMBAQMBgQMCAQMCgQMDAQMDgQMAAYMAgYMBAYMBgYMCAYMCgYMDAYMDgYMAAgMAggMBAgMBggMCAgMCggMDAgMDggMAAoMAgoMBAoMBgoMCAoMCgoMDAoMDgoMAAwMAgwMBAwMBgwMCAwMCgwMD/+/CgoKSAgID/AAAA/wD//wAAAP//AP8A//////9Y0jREAAAAcklEQVR4nM2RMRLAIAgEU/o+v2d7byQliSSiIlJmso06OwqHx/FjcmIhFccRv9DummClXDvrDs8yos7DeayXjCRFsgaglsUG5QkqgWSGrdmywA4JU0O2u/ushZZc1NvMSy5oDHFmkhibdaaMwKnf/s4HXN3GrtfqR9+KAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.06865975e-04]\n",
            " [1.28713763e-06]\n",
            " [7.64518658e-06]\n",
            " [8.28956850e-12]\n",
            " [5.15276719e-09]\n",
            " [2.34980888e-01]\n",
            " [9.74784951e-01]\n",
            " [4.69640718e-12]\n",
            " [3.38070067e-03]\n",
            " [4.16153963e-05]]\n",
            "6.bmp\n",
            "\n",
            "7.bmp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.BmpImagePlugin.BmpImageFile image mode=P size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgIDAwMDA3MCmyvBAIABgIACAIACgIADAIADgIAAAQAAgQABAQABgQACAQACgQADAQADgQAAAYAAgYABAYABgYACAYACgYADAYADgYAAAgAAggABAgABggACAgACggADAgADggAAAoAAgoABAoABgoACAoACgoADAoADgoAAAwAAgwABAwABgwACAwACgwADAwADgwAAA4AAg4ABA4ABg4ACA4ACg4ADA4ADg4AAAAEAgAEBAAEBgAECAAECgAEDAAEDgAEAAIEAgIEBAIEBgIECAIECgIEDAIEDgIEAAQEAgQEBAQEBgQECAQECgQEDAQEDgQEAAYEAgYEBAYEBgYECAYECgYEDAYEDgYEAAgEAggEBAgEBggECAgECggEDAgEDggEAAoEAgoEBAoEBgoECAoECgoEDAoEDgoEAAwEAgwEBAwEBgwECAwECgwEDAwEDgwEAA4EAg4EBA4EBg4ECA4ECg4EDA4EDg4EAAAIAgAIBAAIBgAICAAICgAIDAAIDgAIAAIIAgIIBAIIBgIICAIICgIIDAIIDgIIAAQIAgQIBAQIBgQICAQICgQIDAQIDgQIAAYIAgYIBAYIBgYICAYICgYIDAYIDgYIAAgIAggIBAgIBggICAgICggIDAgIDggIAAoIAgoIBAoIBgoICAoICgoIDAoIDgoIAAwIAgwIBAwIBgwICAwICgwIDAwIDgwIAA4IAg4IBA4IBg4ICA4ICg4IDA4IDg4IAAAMAgAMBAAMBgAMCAAMCgAMDAAMDgAMAAIMAgIMBAIMBgIMCAIMCgIMDAIMDgIMAAQMAgQMBAQMBgQMCAQMCgQMDAQMDgQMAAYMAgYMBAYMBgYMCAYMCgYMDAYMDgYMAAgMAggMBAgMBggMCAgMCggMDAgMDggMAAoMAgoMBAoMBgoMCAoMCgoMDAoMDgoMAAwMAgwMBAwMBgwMCAwMCgwMD/+/CgoKSAgID/AAAA/wD//wAAAP//AP8A//////9Y0jREAAAAV0lEQVR4nM3Quw0AIAgEUErmcz1bZsQSjYnGH9cZvfYFxCN6lcA2heOAi5npgLKiuW8US54pGFQ0CIzQUnjNVkEXPlTQ0ns67RXUTQBfvGH1VLc2AfZNMn7cg7oVvRucAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.32451826e-15]\n",
            " [1.78096139e-06]\n",
            " [5.44622456e-04]\n",
            " [7.12241360e-02]\n",
            " [8.55373129e-11]\n",
            " [4.19629101e-07]\n",
            " [1.07444768e-12]\n",
            " [9.24540232e-01]\n",
            " [4.75226203e-05]\n",
            " [3.19305034e-10]]\n",
            "7.bmp\n",
            "\n",
            "8.bmp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.BmpImagePlugin.BmpImageFile image mode=P size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgIDAwMDA3MCmyvBAIABgIACAIACgIADAIADgIAAAQAAgQABAQABgQACAQACgQADAQADgQAAAYAAgYABAYABgYACAYACgYADAYADgYAAAgAAggABAgABggACAgACggADAgADggAAAoAAgoABAoABgoACAoACgoADAoADgoAAAwAAgwABAwABgwACAwACgwADAwADgwAAA4AAg4ABA4ABg4ACA4ACg4ADA4ADg4AAAAEAgAEBAAEBgAECAAECgAEDAAEDgAEAAIEAgIEBAIEBgIECAIECgIEDAIEDgIEAAQEAgQEBAQEBgQECAQECgQEDAQEDgQEAAYEAgYEBAYEBgYECAYECgYEDAYEDgYEAAgEAggEBAgEBggECAgECggEDAgEDggEAAoEAgoEBAoEBgoECAoECgoEDAoEDgoEAAwEAgwEBAwEBgwECAwECgwEDAwEDgwEAA4EAg4EBA4EBg4ECA4ECg4EDA4EDg4EAAAIAgAIBAAIBgAICAAICgAIDAAIDgAIAAIIAgIIBAIIBgIICAIICgIIDAIIDgIIAAQIAgQIBAQIBgQICAQICgQIDAQIDgQIAAYIAgYIBAYIBgYICAYICgYIDAYIDgYIAAgIAggIBAgIBggICAgICggIDAgIDggIAAoIAgoIBAoIBgoICAoICgoIDAoIDgoIAAwIAgwIBAwIBgwICAwICgwIDAwIDgwIAA4IAg4IBA4IBg4ICA4ICg4IDA4IDg4IAAAMAgAMBAAMBgAMCAAMCgAMDAAMDgAMAAIMAgIMBAIMBgIMCAIMCgIMDAIMDgIMAAQMAgQMBAQMBgQMCAQMCgQMDAQMDgQMAAYMAgYMBAYMBgYMCAYMCgYMDAYMDgYMAAgMAggMBAgMBggMCAgMCggMDAgMDggMAAoMAgoMBAoMBgoMCAoMCgoMDAoMDgoMAAwMAgwMBAwMBgwMCAwMCgwMD/+/CgoKSAgID/AAAA/wD//wAAAP//AP8A//////9Y0jREAAAAhklEQVR4nM2RMRLAIAgE7czXaP2erW/EkgSDDgIW6XIV43ocYkp/Vblo6KoBRJpyePqG0FBmGVKCPugOmUnJeIeNCFS4yURqUj2s+1nhYBxH9WDkTOLGJTAyxdMzzRKCzFy6UANpTcv3moNqNr++sJ691k9Fu524+Ik6aRn4ekV2fxoH7KtuYljDxC1JZd4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.23591816e-07]\n",
            " [1.26645670e-05]\n",
            " [2.91580566e-08]\n",
            " [1.62868456e-03]\n",
            " [1.04599330e-06]\n",
            " [2.76838833e-07]\n",
            " [2.96288447e-10]\n",
            " [2.77256572e-05]\n",
            " [9.91266826e-01]\n",
            " [1.50227257e-01]]\n",
            "8.bmp\n",
            "\n",
            "9.bmp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.BmpImagePlugin.BmpImageFile image mode=P size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAADAFBMVEUAAACAAAAAgACAgAAAAICAAIAAgIDAwMDA3MCmyvBAIABgIACAIACgIADAIADgIAAAQAAgQABAQABgQACAQACgQADAQADgQAAAYAAgYABAYABgYACAYACgYADAYADgYAAAgAAggABAgABggACAgACggADAgADggAAAoAAgoABAoABgoACAoACgoADAoADgoAAAwAAgwABAwABgwACAwACgwADAwADgwAAA4AAg4ABA4ABg4ACA4ACg4ADA4ADg4AAAAEAgAEBAAEBgAECAAECgAEDAAEDgAEAAIEAgIEBAIEBgIECAIECgIEDAIEDgIEAAQEAgQEBAQEBgQECAQECgQEDAQEDgQEAAYEAgYEBAYEBgYECAYECgYEDAYEDgYEAAgEAggEBAgEBggECAgECggEDAgEDggEAAoEAgoEBAoEBgoECAoECgoEDAoEDgoEAAwEAgwEBAwEBgwECAwECgwEDAwEDgwEAA4EAg4EBA4EBg4ECA4ECg4EDA4EDg4EAAAIAgAIBAAIBgAICAAICgAIDAAIDgAIAAIIAgIIBAIIBgIICAIICgIIDAIIDgIIAAQIAgQIBAQIBgQICAQICgQIDAQIDgQIAAYIAgYIBAYIBgYICAYICgYIDAYIDgYIAAgIAggIBAgIBggICAgICggIDAgIDggIAAoIAgoIBAoIBgoICAoICgoIDAoIDgoIAAwIAgwIBAwIBgwICAwICgwIDAwIDgwIAA4IAg4IBA4IBg4ICA4ICg4IDA4IDg4IAAAMAgAMBAAMBgAMCAAMCgAMDAAMDgAMAAIMAgIMBAIMBgIMCAIMCgIMDAIMDgIMAAQMAgQMBAQMBgQMCAQMCgQMDAQMDgQMAAYMAgYMBAYMBgYMCAYMCgYMDAYMDgYMAAgMAggMBAgMBggMCAgMCggMDAgMDggMAAoMAgoMBAoMBgoMCAoMCgoMDAoMDgoMAAwMAgwMBAwMBgwMCAwMCgwMD/+/CgoKSAgID/AAAA/wD//wAAAP//AP8A//////9Y0jREAAAAeklEQVR4nL2RsQ7AIAhE2eTXXPk9V78RR6s2WhCN6dDeBL6c50WAj0WYb2EwLHDuYsOylDZTOXG+DD4ZM9U7+9KwgJW5Z9VQMzBO3sKoXkgattCBeYJRdKxzAtjgyTjjZKCI3zF6ZyTsNRZGHB+1SFQ9TOKhRjxV/EkXahO/xolj6rYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.55850590e-07]\n",
            " [3.57391902e-05]\n",
            " [1.95778728e-08]\n",
            " [7.46067633e-01]\n",
            " [7.98407361e-11]\n",
            " [1.46628156e-04]\n",
            " [1.73705848e-06]\n",
            " [1.46061185e-10]\n",
            " [7.96569247e-05]\n",
            " [7.90086539e-04]]\n",
            "9.bmp\n",
            "\n"
          ]
        }
      ]
    }
  ]
}